{"componentChunkName":"component---src-templates-blog-post-js","path":"/assignments/3","result":{"data":{"markdownRemark":{"rawMarkdownBody":"\n# Assignment 3: Deeper Learning\n\n## Preface\n\nIn this assignment, we will be exploring deep learning. This is NOT a machine learning class, so very little math is expected in this assignment, however thinking about the questions mathematically and exercising proper debugging will help.\n\nThis assignment can be completed in an IPython notebook. The starting code is available in a notebook <a href=\"https://raw.githubusercontent.com/CIS192/homework/master/assignment3.ipynb\" download>to download here</a> (you might need to right-click and \"Save As\"). Feel free to use Google Colab or an editor on your own machine. Be warned that part of this assignment involves neural network training, which is computationally expensive and may take a long time on a laptop.\n\nThis assignment will be graded by the staff, so make sure to comment your code and document design considerations. You are allowed to use external libraries if you wish (e.g. `math` or `numpy`).\n\n## Deep Learning Training\n\nIn this section, we will be optimizing the parameters for neural network training, specifically for an image classification task. Note: if you are using Google Colab make sure to change the **Runtime Type to GPU** to speed up training!\n\nThese are some common hyperparameters to experiment with when training neural networks:\n\n1. `batch_size` – smaller batch size = more parameter updates\n2. `Dropout(p)` – randomly sets weights to 0 with probability `p` to prevent overfitting\n3. `optimizer` – change from `SGD` (stochastic gradient descent) to `Adadelta` or another optimizer [here](https://keras.io/optimizers/)\n4. `lr` – larger learning rate = larger step per instance, less granularity\n5. `epochs` – more training batches/passes through the data\n\n**TODO:** Try out **at least three different parameter alterations** and note each final accuracy. To recieve full credit, you must change 3 different hyperparameters (e.g. batch size, learning rate, and epochs), and it may be informative to change a hyperparameter multiple times. In addition, write a sentence or two describing what your high-level intuition is for explaining the performance difference (if any). If you're coding in the notebook environment, feel free to write your explanation in a text cell. We’re not looking for any particular accuracy, we just want an exploration of different hyperparameter tunings and observations of the change in performance.\n\nThere is a lot of jargon involved, so you should consult the [Keras documentation](https://keras.io/api/) or other external resources and ask questions on Piazza. Feel free to make architecture changes (e.g. `model.add()` new layers) if you’re feeling adventurous! However, just changing three hyperparameters (with explanation) is sufficient for full credit.\n\n```python\n'''\nTrains a simple convnet on the MNIST dataset.\nCredit: Keras Team\n'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\n# DEFINING *SOME* HYPERPARAMETERS\nbatch_size = 256\nnum_classes = 10\nepochs = 2\n\n# DATA CLEAN-UP\nimg_rows, img_cols = 28, 28\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\nx_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n# MODEL DEFINITION (some hardcodede hyperparameters)\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.9))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.9))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# MODEL COMPILATION AND TRAINING\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.SGD(lr=0.001),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# MODEL EVALUATION\nscore = model.evaluate(x_test, y_test, verbose=0)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n```\n\n## Word Embeddings\n\nIn this section, we will explore different word embeddings systems using the [Magnitude](https://github.com/plasticityai/magnitude) package and pre-trained word embeddings.\n\nA brief installation (works in Google Colab):\n\n1. `pip install pymagnitude`\n2. `!wget http://magnitude.plasticity.ai/word2vec/light/GoogleNews-vectors-negative300.magnitude`\n\nWe can now instantiate a query-able Magnitude vectors object as follows:\n\n```python\nfrom pymagnitude import *\n\nfile_path = \"GoogleNews-vectors-negative300.magnitude\"\nvectors = Magnitude(filge_path)\nprint(vectors.distance(\"cat\", \"dog\"))\n```\n\nFor this question, create a text cell in your iPython notebook answering the following questions by referring to the Magnitude [documentation](https://github.com/plasticityai/magnitude#using-the-library):\n\n1. What is the dimensionality of these word embeddings? Provide an integer answer.\n2. What are the top-5 most similar words to `picnic` (not including `picnic` itself)?\n3. According to the word embeddings, which of these words is not like the others? `[tissue', 'papyrus', 'manila', 'newsprint', 'parchment', 'gazette’]`\n4. Use the word embeddings to solve the following analogy: “leg is to jump as `X` is to throw”.\n5. Is the word `alumni` in the vocabulary? What about `alumnus`?\n6. How many words are in the vocabulary?\n","html":"<h1>Assignment 3: Deeper Learning</h1>\n<h2>Preface</h2>\n<p>In this assignment, we will be exploring deep learning. This is NOT a machine learning class, so very little math is expected in this assignment, however thinking about the questions mathematically and exercising proper debugging will help.</p>\n<p>This assignment can be completed in an IPython notebook. The starting code is available in a notebook <a href=\"https://raw.githubusercontent.com/CIS192/homework/master/assignment3.ipynb\" download>to download here</a> (you might need to right-click and \"Save As\"). Feel free to use Google Colab or an editor on your own machine. Be warned that part of this assignment involves neural network training, which is computationally expensive and may take a long time on a laptop.</p>\n<p>This assignment will be graded by the staff, so make sure to comment your code and document design considerations. You are allowed to use external libraries if you wish (e.g. <code class=\"language-text\">math</code> or <code class=\"language-text\">numpy</code>).</p>\n<h2>Deep Learning Training</h2>\n<p>In this section, we will be optimizing the parameters for neural network training, specifically for an image classification task. Note: if you are using Google Colab make sure to change the <strong>Runtime Type to GPU</strong> to speed up training!</p>\n<p>These are some common hyperparameters to experiment with when training neural networks:</p>\n<ol>\n<li><code class=\"language-text\">batch_size</code> – smaller batch size = more parameter updates</li>\n<li><code class=\"language-text\">Dropout(p)</code> – randomly sets weights to 0 with probability <code class=\"language-text\">p</code> to prevent overfitting</li>\n<li><code class=\"language-text\">optimizer</code> – change from <code class=\"language-text\">SGD</code> (stochastic gradient descent) to <code class=\"language-text\">Adadelta</code> or another optimizer <a href=\"https://keras.io/optimizers/\">here</a></li>\n<li><code class=\"language-text\">lr</code> – larger learning rate = larger step per instance, less granularity</li>\n<li><code class=\"language-text\">epochs</code> – more training batches/passes through the data</li>\n</ol>\n<p><strong>TODO:</strong> Try out <strong>at least three different parameter alterations</strong> and note each final accuracy. To recieve full credit, you must change 3 different hyperparameters (e.g. batch size, learning rate, and epochs), and it may be informative to change a hyperparameter multiple times. In addition, write a sentence or two describing what your high-level intuition is for explaining the performance difference (if any). If you're coding in the notebook environment, feel free to write your explanation in a text cell. We’re not looking for any particular accuracy, we just want an exploration of different hyperparameter tunings and observations of the change in performance.</p>\n<p>There is a lot of jargon involved, so you should consult the <a href=\"https://keras.io/api/\">Keras documentation</a> or other external resources and ask questions on Piazza. Feel free to make architecture changes (e.g. <code class=\"language-text\">model.add()</code> new layers) if you’re feeling adventurous! However, just changing three hyperparameters (with explanation) is sufficient for full credit.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token triple-quoted-string string\">'''\nTrains a simple convnet on the MNIST dataset.\nCredit: Keras Team\n'''</span>\n\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> print_function\n<span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> mnist\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Dropout<span class=\"token punctuation\">,</span> Flatten\n<span class=\"token keyword\">from</span> keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Conv2D<span class=\"token punctuation\">,</span> MaxPooling2D\n\n<span class=\"token comment\"># DEFINING *SOME* HYPERPARAMETERS</span>\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">256</span>\nnum_classes <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\nepochs <span class=\"token operator\">=</span> <span class=\"token number\">2</span>\n\n<span class=\"token comment\"># DATA CLEAN-UP</span>\nimg_rows<span class=\"token punctuation\">,</span> img_cols <span class=\"token operator\">=</span> <span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span>\n\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nx_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> img_rows<span class=\"token punctuation\">,</span> img_cols<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nx_test <span class=\"token operator\">=</span> x_test<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> img_rows<span class=\"token punctuation\">,</span> img_cols<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ninput_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>img_rows<span class=\"token punctuation\">,</span> img_cols<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\nx_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span>\nx_test <span class=\"token operator\">=</span> x_test<span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span>\nx_train <span class=\"token operator\">/=</span> <span class=\"token number\">255</span>\nx_test <span class=\"token operator\">/=</span> <span class=\"token number\">255</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_train shape:'</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'train samples'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'test samples'</span><span class=\"token punctuation\">)</span>\n\ny_train <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>to_categorical<span class=\"token punctuation\">(</span>y_train<span class=\"token punctuation\">,</span> num_classes<span class=\"token punctuation\">)</span>\ny_test <span class=\"token operator\">=</span> keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>to_categorical<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> num_classes<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># MODEL DEFINITION (some hardcodede hyperparameters)</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span>input_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>MaxPooling2D<span class=\"token punctuation\">(</span>pool_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span>num_classes<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># MODEL COMPILATION AND TRAINING</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>categorical_crossentropy<span class=\"token punctuation\">,</span>\n              optimizer<span class=\"token operator\">=</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span>\n          batch_size<span class=\"token operator\">=</span>batch_size<span class=\"token punctuation\">,</span>\n          epochs<span class=\"token operator\">=</span>epochs<span class=\"token punctuation\">,</span>\n          verbose<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          validation_data<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># MODEL EVALUATION</span>\nscore <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Test loss:'</span><span class=\"token punctuation\">,</span> score<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Test accuracy:'</span><span class=\"token punctuation\">,</span> score<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Word Embeddings</h2>\n<p>In this section, we will explore different word embeddings systems using the <a href=\"https://github.com/plasticityai/magnitude\">Magnitude</a> package and pre-trained word embeddings.</p>\n<p>A brief installation (works in Google Colab):</p>\n<ol>\n<li><code class=\"language-text\">pip install pymagnitude</code></li>\n<li><code class=\"language-text\">!wget http://magnitude.plasticity.ai/word2vec/light/GoogleNews-vectors-negative300.magnitude</code></li>\n</ol>\n<p>We can now instantiate a query-able Magnitude vectors object as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pymagnitude <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n\nfile_path <span class=\"token operator\">=</span> <span class=\"token string\">\"GoogleNews-vectors-negative300.magnitude\"</span>\nvectors <span class=\"token operator\">=</span> Magnitude<span class=\"token punctuation\">(</span>filge_path<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>vectors<span class=\"token punctuation\">.</span>distance<span class=\"token punctuation\">(</span><span class=\"token string\">\"cat\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dog\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>For this question, create a text cell in your iPython notebook answering the following questions by referring to the Magnitude <a href=\"https://github.com/plasticityai/magnitude#using-the-library\">documentation</a>:</p>\n<ol>\n<li>What is the dimensionality of these word embeddings? Provide an integer answer.</li>\n<li>What are the top-5 most similar words to <code class=\"language-text\">picnic</code> (not including <code class=\"language-text\">picnic</code> itself)?</li>\n<li>According to the word embeddings, which of these words is not like the others? <code class=\"language-text\">[tissue&#39;, &#39;papyrus&#39;, &#39;manila&#39;, &#39;newsprint&#39;, &#39;parchment&#39;, &#39;gazette’]</code></li>\n<li>Use the word embeddings to solve the following analogy: “leg is to jump as <code class=\"language-text\">X</code> is to throw”.</li>\n<li>Is the word <code class=\"language-text\">alumni</code> in the vocabulary? What about <code class=\"language-text\">alumnus</code>?</li>\n<li>How many words are in the vocabulary?</li>\n</ol>"}},"pageContext":{"pathSlug":"/assignments/3"}},"staticQueryHashes":[]}