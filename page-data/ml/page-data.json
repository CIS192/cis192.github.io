{"componentChunkName":"component---src-templates-blog-post-js","path":"/ml","result":{"data":{"markdownRemark":{"rawMarkdownBody":"\n# Machine Learning and Data Science\n\nIn lecture, we talked about how **Machine Learning** just boils down to making predictions about the world, given adequete data. We also learned about a variety of different techniques for the machine learning process, namely data pre-processing and splitting data into a training/test split.\n\nSlides from lecture are available [here](https://kirubarajan.nyc3.digitaloceanspaces.com/spring2020/Machine%20Learning%20I.pdf).\n\n## About Pandas and Sci-Kit Learn\n\nRecall from lecture that Pandas is a library that gives us a framework for loading and manipulating data. Data is stored in a spreadsheet-like format of a `DataFrame`, which we can initialize from a `.csv` file (along with a list of dictionaries or by inserting rows into programatically). In addition to Pandas, we will also make use of .\n\n## Analyzing Cereal\n\nIn lecture, we took a look at the [Cereal Dataset](https://www.kaggle.com/crawford/80-cereals) from Kaggle.\n\n### Working With Files\n\nWe used the following script to read in the `\"cereal.csv\"` file with Pandas:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndef get_cereal_df(input_path):\n    return pd.read_csv(input_path)\n\n\ndef visualize_data(df):\n    plt.scatter(df['calories'], df['sugars'])\n    plt.show()\n\n\nif __name__ == '__main__':\n    df = get_cereal_df('cereal.csv')\n    visualize_data(df)\n```\n\nNote that the code under the `if` statement is only run when we execute the script via the command line (i.e. `python3 data.py`). This is to ensure that we can later import functionality from this module without running all the code in the script.\n\n### Training a Machine Learning Model\n\nFinally, we trained a machine learning model named `KNeighborsRegressor` to predict the rating of a cereal, given it's sugar and calories as **features**. The model is a variant of the K-Nearest Neighbours classifier discussed in class. However, the model performs a _regression_ task of predicting a continuous value, rather than a discrete one.\n\nWe first `import` the data points via `get_cereal_df`, partition the data into a training and testing splits, and then train the classifier:\n\n```python\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nfrom data import get_cereal_df\n\n\nif __name__ == '__main__':\n    df = get_cereal_df('cereal.csv')\n\n    train_features, test_features = train_test_split(df[['sugars', 'calories']], test_size=0.2)\n    train_labels, test_labels = train_test_split(df[['calories']], test_size=0.2)\n\n    model = KNeighborsRegressor(n_neighbors=9)\n    model.fit(train_features, train_labels) # ---> does the training!\n\n    print(model.score(test_features, test_labels))\n```\n\nOur final line prints the model's evaluation score, which you can read about [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.score).\n\n## Conclusion\n\nThere are many different third-party tools and frameworks that make machine learning easy in Python. We discussed in class how they use [Cython](https://cython.org/) to speed up the performance of the code, and this will become more apparent in the following week's lectures, when we look into Natural Language Processing and Deep Learning!","html":"<h1>Machine Learning and Data Science</h1>\n<p>In lecture, we talked about how <strong>Machine Learning</strong> just boils down to making predictions about the world, given adequete data. We also learned about a variety of different techniques for the machine learning process, namely data pre-processing and splitting data into a training/test split.</p>\n<p>Slides from lecture are available <a href=\"https://kirubarajan.nyc3.digitaloceanspaces.com/spring2020/Machine%20Learning%20I.pdf\">here</a>.</p>\n<h2>About Pandas and Sci-Kit Learn</h2>\n<p>Recall from lecture that Pandas is a library that gives us a framework for loading and manipulating data. Data is stored in a spreadsheet-like format of a <code class=\"language-text\">DataFrame</code>, which we can initialize from a <code class=\"language-text\">.csv</code> file (along with a list of dictionaries or by inserting rows into programatically). In addition to Pandas, we will also make use of .</p>\n<h2>Analyzing Cereal</h2>\n<p>In lecture, we took a look at the <a href=\"https://www.kaggle.com/crawford/80-cereals\">Cereal Dataset</a> from Kaggle.</p>\n<h3>Working With Files</h3>\n<p>We used the following script to read in the <code class=\"language-text\">&quot;cereal.csv&quot;</code> file with Pandas:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_cereal_df</span><span class=\"token punctuation\">(</span>input_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>input_path<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">visualize_data</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    plt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'calories'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'sugars'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    df <span class=\"token operator\">=</span> get_cereal_df<span class=\"token punctuation\">(</span><span class=\"token string\">'cereal.csv'</span><span class=\"token punctuation\">)</span>\n    visualize_data<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Note that the code under the <code class=\"language-text\">if</code> statement is only run when we execute the script via the command line (i.e. <code class=\"language-text\">python3 data.py</code>). This is to ensure that we can later import functionality from this module without running all the code in the script.</p>\n<h3>Training a Machine Learning Model</h3>\n<p>Finally, we trained a machine learning model named <code class=\"language-text\">KNeighborsRegressor</code> to predict the rating of a cereal, given it's sugar and calories as <strong>features</strong>. The model is a variant of the K-Nearest Neighbours classifier discussed in class. However, the model performs a <em>regression</em> task of predicting a continuous value, rather than a discrete one.</p>\n<p>We first <code class=\"language-text\">import</code> the data points via <code class=\"language-text\">get_cereal_df</code>, partition the data into a training and testing splits, and then train the classifier:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>neighbors <span class=\"token keyword\">import</span> KNeighborsRegressor\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> data <span class=\"token keyword\">import</span> get_cereal_df\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    df <span class=\"token operator\">=</span> get_cereal_df<span class=\"token punctuation\">(</span><span class=\"token string\">'cereal.csv'</span><span class=\"token punctuation\">)</span>\n\n    train_features<span class=\"token punctuation\">,</span> test_features <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sugars'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'calories'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\n    train_labels<span class=\"token punctuation\">,</span> test_labels <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'calories'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\n\n    model <span class=\"token operator\">=</span> KNeighborsRegressor<span class=\"token punctuation\">(</span>n_neighbors<span class=\"token operator\">=</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span>\n    model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_features<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">)</span> <span class=\"token comment\"># ---> does the training!</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>test_features<span class=\"token punctuation\">,</span> test_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Our final line prints the model's evaluation score, which you can read about <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.score\">here</a>.</p>\n<h2>Conclusion</h2>\n<p>There are many different third-party tools and frameworks that make machine learning easy in Python. We discussed in class how they use <a href=\"https://cython.org/\">Cython</a> to speed up the performance of the code, and this will become more apparent in the following week's lectures, when we look into Natural Language Processing and Deep Learning!</p>"}},"pageContext":{"pathSlug":"/ml"}},"staticQueryHashes":[]}